{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62babec",
   "metadata": {},
   "source": [
    "Bimatrix games, different equilibria\n",
    "    - Generate list of matrices (m1 = round 1)\n",
    "    - Pure nash\n",
    "    - Mixed nash\n",
    "    - Prisoners' dilemma\n",
    "    - RPS\n",
    "    - Skip coarse-correlated equilibriums\n",
    "\n",
    "FTL, OL, FTRL (regularized based on how recent the feedback was - *constant/i )\n",
    "  A   B\n",
    "X AX  BX\n",
    "Y AY  BY\n",
    "Online Learning\n",
    "    - Given opponent took action X, we give alg AX, BX\n",
    "MAB\n",
    "    - Given opponent took action X and we took action A, we give MAB just AX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5854e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[[0.66, 0.72], [0.83, 0.9]], [[0.12, 0.44], [0.48, 0.24]]], [(array([1., 0.]), array([0., 1.]))])\n",
      "([[[3, 5], [3, 15]], [[18, 5], [1, 2]]], [1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[[1, 1], [8, 12], [19, 6]],\n",
       "  [[12, 8], [1, 1], [9, 19]],\n",
       "  [[6, 19], [19, 9], [1, 1]]],\n",
       " [(array([0.43703704, 0.27407407, 0.28888889]),\n",
       "   array([0.43703704, 0.27407407, 0.28888889]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import random\n",
    "import nashpy as nash\n",
    "import numpy as np\n",
    "\n",
    "def rand_decimal():\n",
    "    return random.randrange(0, 99)/100\n",
    "\n",
    "def find_max_payoffs(payoff_matrix):\n",
    "    max_row_payoff, max_col_payoff = 0, 0\n",
    "    for row in payoff_matrix:\n",
    "        for payoffs in row:\n",
    "            row_payoff = payoffs[0]\n",
    "            col_payoff = payoffs[1]\n",
    "            if row_payoff > max_row_payoff: max_row_payoff = row_payoff\n",
    "            if col_payoff > max_col_payoff: max_col_payoff = col_payoff \n",
    "    return max_row_payoff, max_col_payoff\n",
    "\n",
    "def generate_dominant_strategy(num_actions=2, num_rounds=1):\n",
    "    row_dominant, col_dominant = random.randrange(0, num_actions), random.randrange(0, num_actions)\n",
    "    print(row_dominant, col_dominant)\n",
    "    #generate randomized payoff matrix\n",
    "    payoff_matrix = [[[rand_decimal(), rand_decimal()] for i in range(num_actions)] for i in range(num_actions)]\n",
    "    \n",
    "    #overwrite payoffs of dominant row and col with 'dominant' payoffs (random values that are higher than the max payoff)\n",
    "    max_row_payoff, max_col_payoff = find_max_payoffs(payoff_matrix)             \n",
    "    for row in payoff_matrix:\n",
    "        row[col_dominant][1] = random.randrange(int(max_col_payoff*100), 100)/100\n",
    "    for payoff in payoff_matrix[row_dominant]:\n",
    "        payoff[0] = random.randrange(int(max_row_payoff*100), 100)/100\n",
    "        \n",
    "    return payoff_matrix\n",
    "\n",
    "def is_pure_nash(row, col, payoff_matrix, num_actions):\n",
    "    row_player_val, col_player_val = payoff_matrix[row][col][0], payoff_matrix[row][col][1]\n",
    "    for i in range(num_actions):\n",
    "        if payoff_matrix[row][i][1] > col_player_val: return False\n",
    "        if payoff_matrix[i][col][0] > row_player_val: return False\n",
    "    return True\n",
    "\n",
    "def add_pure_nash(payoff_matrix, num_actions):\n",
    "    print('pre-added')\n",
    "    print(payoff_matrix)\n",
    "    pnash_row, pnash_col = random.randrange(0, num_actions), random.randrange(0, num_actions)\n",
    "    old_row_val, old_col_val = payoff_matrix[pnash_row][pnash_col][0], payoff_matrix[pnash_row][pnash_col][1]\n",
    "    row_max, col_max = 0, 0\n",
    "    row_max_index, col_max_index = None, None\n",
    "    for i in range(num_actions):\n",
    "        if payoff_matrix[pnash_row][i][1] > col_max: \n",
    "            col_max = payoff_matrix[pnash_row][i][1]\n",
    "            col_max_index = i\n",
    "            \n",
    "        if payoff_matrix[i][pnash_col][0] > row_max: \n",
    "            row_max = payoff_matrix[i][pnash_col][0]\n",
    "            row_max_index = i\n",
    "    \n",
    "    col_max_loc = payoff_matrix[pnash_row][col_max_index]\n",
    "    row_max_loc = payoff_matrix[row_max_index][pnash_col]\n",
    "    col_max_loc[1], payoff_matrix[pnash_row][pnash_col][1] = old_col_val, col_max\n",
    "    row_max_loc[0], payoff_matrix[pnash_row][pnash_col][0] = old_row_val, row_max\n",
    "    print('added')\n",
    "    return [pnash_row, pnash_col]\n",
    "    \n",
    "\n",
    "def generate_pure_nash(num_actions=2, num_rounds=1):\n",
    "    payoff_matrix = [[[rand_decimal(), rand_decimal()] for i in range(num_actions)] for i in range(num_actions)]\n",
    "    pure_nash_list = []\n",
    "    for row in range(num_actions):\n",
    "        for col in range(num_actions):\n",
    "            if is_pure_nash(row, col, payoff_matrix, num_actions): pure_nash_list.append([row, col])\n",
    "    # if no pure nash randomly generated, recreate one\n",
    "    if pure_nash_list == []:\n",
    "        new_nash = add_pure_nash(payoff_matrix, num_actions)\n",
    "        pure_nash_list.append(new_nash)\n",
    "    \n",
    "    print(payoff_matrix)\n",
    "    print(pure_nash_list)\n",
    "    return payoff_matrix, pure_nash_list\n",
    "\n",
    "def generate_any_nash(num_actions=2, num_rounds=1):\n",
    "    #generate randomized payoff matrix, may have pure or mixed nash equilibrium(s)\n",
    "    payoff_matrix = [[[rand_decimal(), rand_decimal()] for i in range(num_actions)] for i in range(num_actions)]\n",
    "    row_player_payoffs = []\n",
    "    col_player_payoffs = []\n",
    "    for row in payoff_matrix:\n",
    "        new_cplayer_row = []\n",
    "        new_rplayer_row = []\n",
    "        for payoff in row:\n",
    "            new_cplayer_row.append(payoff[1])\n",
    "            new_rplayer_row.append(payoff[0])\n",
    "        row_player_payoffs.append(new_rplayer_row)\n",
    "        col_player_payoffs.append(new_cplayer_row)\n",
    "    \n",
    "    A = np.array(row_player_payoffs)\n",
    "    B = np.array(col_player_payoffs)\n",
    "    game = nash.Game(A, B)\n",
    "    equilibria = game.support_enumeration()\n",
    "    eq_list = []\n",
    "    for eq in equilibria:\n",
    "        eq_list.append(eq)\n",
    "    return payoff_matrix, eq_list\n",
    "\n",
    "def generate_prisoners():\n",
    "    row_cooperate_payoff, col_cooperate_payoff = random.randrange(3, 6), random.randrange(3, 6)\n",
    "    row_betray_payoff, col_betray_payoff = random.randrange(10, 20), random.randrange(10, 20)\n",
    "    row_double_betray_payoff, col_double_betray_payoff = random.randrange(0, 3), random.randrange(0, 3)\n",
    "    payoff_matrix = [\n",
    "        [[row_cooperate_payoff, col_cooperate_payoff], [row_cooperate_payoff, col_betray_payoff]],\n",
    "        [[row_betray_payoff, col_cooperate_payoff], [row_double_betray_payoff, col_double_betray_payoff]]\n",
    "    ]\n",
    "    eq_list = [1, 1]\n",
    "    return payoff_matrix, eq_list\n",
    "\n",
    "def generate_rps():\n",
    "    rock_win_payoff = random.randrange(10, 20)\n",
    "    paper_win_payoff = random.randrange(10, 20)\n",
    "    scissors_win_payoff = random.randrange(10, 20)\n",
    "    tie_payoff = random.randrange(0, 3)\n",
    "    rock_loss_payoff = random.randrange(5, 10)\n",
    "    paper_loss_payoff = random.randrange(5, 10)\n",
    "    scissors_loss_payoff = random.randrange(5, 10)\n",
    "    payoff_matrix = [\n",
    "        [[tie_payoff, tie_payoff], [rock_loss_payoff, paper_win_payoff], [rock_win_payoff, scissors_loss_payoff]],\n",
    "        [[paper_win_payoff, rock_loss_payoff], [tie_payoff, tie_payoff], [paper_loss_payoff, scissors_win_payoff]],\n",
    "        [[scissors_loss_payoff, rock_win_payoff], [scissors_win_payoff, paper_loss_payoff], [tie_payoff, tie_payoff]]\n",
    "    ]\n",
    "    row_player_payoffs = []\n",
    "    col_player_payoffs = []\n",
    "    for row in payoff_matrix:\n",
    "        new_cplayer_row = []\n",
    "        new_rplayer_row = []\n",
    "        for payoff in row:\n",
    "            new_cplayer_row.append(payoff[1])\n",
    "            new_rplayer_row.append(payoff[0])\n",
    "        row_player_payoffs.append(new_rplayer_row)\n",
    "        col_player_payoffs.append(new_cplayer_row)\n",
    "    \n",
    "    A = np.array(row_player_payoffs)\n",
    "    B = np.array(col_player_payoffs)\n",
    "    game = nash.Game(A, B)\n",
    "    equilibria = game.support_enumeration()\n",
    "    eq_list = []\n",
    "    for eq in equilibria:\n",
    "        eq_list.append(eq)\n",
    "    \n",
    "    return payoff_matrix, eq_list\n",
    "\n",
    "print(generate_any_nash())\n",
    "print(generate_prisoners())\n",
    "generate_rps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bcebc8",
   "metadata": {},
   "source": [
    "## Multi-Armed Bandit Online Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17934edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for reference\n",
    "\n",
    "def exponential_weights(curr_payoffs, cumulative_payoffs, epsilon, num_actions):\n",
    "    choices_made = []\n",
    "    action_weights = []\n",
    "    action_probabilities = [(1/num_actions) for i in range(num_actions)]\n",
    "    current_weights = [1 for i in range(num_actions)]\n",
    "    action_weights.append(current_weights)\n",
    "    alg_payoffs = []\n",
    "    opt_payoffs = []\n",
    "    \n",
    "    for round in range(1, num_rounds):\n",
    "        last_round = round - 1\n",
    "        current_weights = [None for i in range(num_actions)]\n",
    "        for action in range(num_actions):\n",
    "            V_last = totals_by_round[last_round][action]\n",
    "            exp = V_last / max_payoff\n",
    "            current_weights[action] = pow(1 + epsilon, exp)\n",
    "        #randomly select from actions using weights as probabilities\n",
    "        selected_payoff = random.choices(rounds_list[round], weights=current_weights, k=1)[0]\n",
    "        alg_payoffs.append(selected_payoff)  \n",
    "        opt_payoffs.append(max(rounds_list[round]))\n",
    "        action_weights.append(current_weights)\n",
    "        \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57bb742c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1128789696.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [15]\u001b[1;36m\u001b[0m\n\u001b[1;33m    cumulative_payoffs +=\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def multi_band_alg(epsilon, game_matrix, rounds): \n",
    "    actions = len(game_matrix)\n",
    "    probabilities = [1/actions for i in range(actions)]\n",
    "    cumulative_payoffs = [0 for i in range(actions)]\n",
    "    indices = []\n",
    "    for i in range(len(game_matrix)):\n",
    "        indices.append(i)\n",
    "        \n",
    "    for j in range(1,rounds):\n",
    "        selected_index = random.choices(indices, weights=probabilities, k=1)[0]\n",
    "        selected_action = game_matrix[selected_index]\n",
    "        \n",
    "        ##opponent action !!\n",
    "        \n",
    "        explore_exploit_prob = (1-epsilon) * probabilities[selected_index] + (epsilon/actions)\n",
    "        for k in range(actions):\n",
    "            if k == selected_index: \n",
    "                curr_payoffs[k] = game_matrix[selected_index]\n",
    "                cumulative_payoffs += \n",
    "                \n",
    "        ola_payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9457455c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (3209559068.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [16]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def FTL_regularization():\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "def FTL_regularization():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59835e",
   "metadata": {},
   "source": [
    "# Algorithm Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c8d86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialWeights:\n",
    "    \n",
    "    def __init__(self, epsilon, num_actions=2):\n",
    "        self.weights_vector = [1 for i in range(num_actions)]\n",
    "        self.totals_by_round = []\n",
    "        self.payoffs_by_round = []\n",
    "        self.choices_by_round = []\n",
    "        self.actions_list = [i for i in range(num_actions)]\n",
    "        self.epsilon = epsilon\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "    def reset_instance(epsilon, num_actions=2):\n",
    "        self.weights_vector = [1 for i in range(num_actions)]\n",
    "        self.totals_by_round = []\n",
    "        self.payoffs_by_round = []\n",
    "        self.choices_by_round = []\n",
    "        self.actions_list = [i for i in range(num_actions)]\n",
    "        self.epsilon = epsilon\n",
    "        self.num_actions = num_actions\n",
    "    \n",
    "    def choose_action(self, max_payoff):\n",
    "        # find weights\n",
    "        current_weights = [None for i in range(self.num_actions)]\n",
    "        for action in range(self.num_actions):\n",
    "            if self.totals_by_round == []:\n",
    "                V_last = 0\n",
    "            else:\n",
    "                V_last = self.totals_by_round[-1][action]\n",
    "            exp = V_last / max_payoff\n",
    "            current_weights[action] = pow(1 + self.epsilon, exp)\n",
    "        # randomly select from actions using weights as probabilities\n",
    "        selected_action = random.choices(self.actions_list, weights=current_weights, k=1)[0]\n",
    "        self.choices_by_round.append(selected_action)\n",
    "        self.weights_vector.append(current_weights)\n",
    "        return selected_action\n",
    "    \n",
    "    def process_payoff(self, selected_payoff, payoff_list):\n",
    "        # add new payoffs to totals, add payoff choice this round to payoffs matrix\n",
    "        self.payoffs_by_round.append(selected_payoff)\n",
    "        if self.totals_by_round == []: \n",
    "            self.totals_by_round.append([payoff_list[i] for i in range(self.num_actions)])\n",
    "        else:\n",
    "            last_round_totals = self.totals_by_round[-1]\n",
    "            self.totals_by_round.append([last_round_totals[i] + payoff_list[i] for i in range(self.num_actions)])\n",
    "                \n",
    "            \n",
    "    #NOTE: totals_by_round[-1] at the end of the simulation will help find 'OPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adabd99",
   "metadata": {},
   "source": [
    "# Matchup Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee556ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "[0.42, 0.9]\n",
      "[0.98, 0.98]\n",
      "[0.42, 0.9]\n",
      "[0.98, 0.98]\n",
      "[0.04, 0.94]\n",
      "[0.98, 0.98]\n",
      "[0.42, 0.9]\n",
      "[0.98, 0.98]\n",
      "[0.04, 0.94]\n",
      "[0.92, 0.99]\n",
      "[0.42, 0.9]\n",
      "[0.92, 0.99]\n",
      "[0.42, 0.9]\n",
      "[0.98, 0.98]\n",
      "[0.04, 0.94]\n",
      "[0.98, 0.98]\n",
      "[0.42, 0.9]\n",
      "[0.98, 0.98]\n",
      "[0.04, 0.94]\n",
      "[0.92, 0.99]\n",
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "([0.9, 0.45, 0.3133333333333334, 0.22499999999999998, 0.188, 0.30000000000000004, 0.32571428571428573, 0.2899999999999999, 0.25333333333333324, 0.23199999999999985], [0.98, 0.49, 0.32666666666666666, 0.245, 0.19800000000000004, 0.17666666666666675, 0.1500000000000001, 0.1312500000000001, 0.11666666666666675, 0.10600000000000005])\n"
     ]
    }
   ],
   "source": [
    "# helpers to find regret of an algorithm\n",
    "def sum_to_round_i(alg_payoffs, current_round):\n",
    "    total = 0\n",
    "    for i in range(current_round):\n",
    "        total += alg_payoffs[i]\n",
    "    return total\n",
    "\n",
    "def individual_regrets(alg_payoffs, round_totals):\n",
    "    final_payoffs = round_totals[-1]\n",
    "    opt_action = final_payoffs.index(max(final_payoffs))\n",
    "    #print(opt_action)\n",
    "    individual_regrets = [0 for i in range(len(alg_payoffs))]\n",
    "    for round in range((len(alg_payoffs))):\n",
    "        individual_regrets[round] = (round_totals[round][opt_action] - sum_to_round_i(alg_payoffs, round)) / (round + 1)\n",
    "    return individual_regrets\n",
    "\n",
    "#takes two instantiations of algorithm classes as inputs\n",
    "def matchup_simulator(alg1, alg2, payoff_matrix, num_rounds, max_payoff):\n",
    "    num_actions = len(payoff_matrix)\n",
    "    for round in range(num_rounds):\n",
    "        # determine which action each algorithm picks\n",
    "        alg1_action = alg1.choose_action(max_payoff)\n",
    "        alg2_action = alg2.choose_action(max_payoff)\n",
    "        \n",
    "        # determine the payoffs and payoff lists for the algorithm combination\n",
    "        payoff_cell = payoff_matrix[alg1_action][alg2_action]\n",
    "        alg1_payoff, alg2_payoff = payoff_cell[0], payoff_cell[1]        \n",
    "        alg1_payoff_list, alg2_payoff_list = [], []\n",
    "        for i in range(num_actions):\n",
    "            alg1_payoff_list.append(payoff_matrix[i][alg2_action][0])\n",
    "            alg2_payoff_list.append(payoff_matrix[alg1_action][i][1])\n",
    "            \n",
    "        # process the payoffs for the algorithm combination to prep alg1, alg2 for the next rou d    \n",
    "        alg1.process_payoff(alg1_payoff, alg1_payoff_list)\n",
    "        alg2.process_payoff(alg2_payoff, alg2_payoff_list)\n",
    "    print(alg1.choices_by_round)\n",
    "    print(alg2.choices_by_round)\n",
    "    # find the regret at each round, return the regret list for each algorithm\n",
    "    alg1_regrets = individual_regrets(alg1.payoffs_by_round, alg1.totals_by_round)\n",
    "    alg2_regrets = individual_regrets(alg2.payoffs_by_round, alg2.totals_by_round)\n",
    "    return alg1_regrets, alg2_regrets \n",
    "\n",
    "payoff_matrix = generate_dominant_strategy()\n",
    "alg1 = ExponentialWeights(0)\n",
    "alg2 = ExponentialWeights(1.0)\n",
    "print(matchup_simulator(alg1, alg2, payoff_matrix, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058859a",
   "metadata": {},
   "source": [
    "# Monte Carlo Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a93dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_trial(alg1, alg2, payoff_matrix_list):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
