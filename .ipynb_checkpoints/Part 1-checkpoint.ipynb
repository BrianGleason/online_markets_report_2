{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e4d158",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a543f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "import math\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26912867",
   "metadata": {},
   "source": [
    "## Generate Distribution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e76197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sorted_indexes(payoffs):\n",
    "    vals_indexes=[]\n",
    "    ind_by_val = []\n",
    "\n",
    "    for i in range(len(payoffs)):\n",
    "        vals_indexes.append([payoffs[i],i])\n",
    "    \n",
    "    vals_indexes.sort(reverse=True)\n",
    "    for x in vals_indexes:\n",
    "        ind_by_val.append(x[1])\n",
    "    return ind_by_val\n",
    "\n",
    "def find_min_index(payoffs):\n",
    "    min_value = min(payoffs)\n",
    "    min_index = payoffs.index(min_value)\n",
    "    return min_index\n",
    "\n",
    "\n",
    "def generate_adversarial_payoffs(num_actions, num_rounds):\n",
    "    rounds_list = []\n",
    "    totals_by_round = []\n",
    "    initial_payoff = round(random.random(), 2)\n",
    "    first_payoffs = [0 for i in range(num_actions)]\n",
    "    first_payoffs[random.randrange(num_actions)] = initial_payoff\n",
    "    total_payoffs = [first_payoffs[i] for i in range(num_actions)]\n",
    "    min_index = find_min_index(total_payoffs)\n",
    "    rounds_list.append(first_payoffs)\n",
    "    totals_by_round.append([total_payoffs[i] for i in range(num_actions)])\n",
    "    \n",
    "    for i in range(num_rounds - 1):\n",
    "        new_payoff = round(random.random(), 2)\n",
    "        adversarial_payoffs = [0 for i in range(num_actions)]\n",
    "        adversarial_payoffs[min_index] = new_payoff\n",
    "        for i in range(num_actions):\n",
    "            total_payoffs[i] += adversarial_payoffs[i]\n",
    "            total_payoffs[i] = round(total_payoffs[i], 2)\n",
    "        \n",
    "        min_index = find_min_index(total_payoffs)\n",
    "        new_totals = [total_payoffs[i] for i in range(num_actions)]\n",
    "        totals_by_round.append(new_totals)\n",
    "        rounds_list.append(adversarial_payoffs)\n",
    "\n",
    "    #print(\"utility at each round: \\n\", rounds_list)\n",
    "    #print(\"totals by round: \\n\", totals_by_round)\n",
    "    #print(\"final payoffs: \\n\", total_payoffs)\n",
    "    return rounds_list, totals_by_round\n",
    "\n",
    "\n",
    "#generate_adversarial_payoffs(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e786cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when generating the bernoulli payoffs, generate the payoffs of each action at each round and the \n",
    "#total payoffs up to that point for each action. i.e. list of lists of payoffs/round & list of lists of aggregated payoffs.\n",
    "#uncomment the last line of the generate_adversarial_payoffs section for an example\n",
    "def find_payoff(success_chance):\n",
    "    comparison_val = random.random()\n",
    "    return int(success_chance > comparison_val)\n",
    "\n",
    "def generate_bernoulli_payoffs(num_actions, num_rounds):\n",
    "    rounds_list = []\n",
    "    totals_by_round = []\n",
    "    total_payoffs = [0 for i in range(num_actions)]\n",
    "    totals_by_round = []\n",
    "    action_success_chances = [round(random.random() / 2,2) for i in range(num_actions)]\n",
    "    \n",
    "    for i in range(num_rounds):\n",
    "        new_payoffs = [find_payoff(action_success_chances[j]) for j in range(num_actions)]\n",
    "        \n",
    "        for i in range(num_actions):\n",
    "            total_payoffs[i] += new_payoffs[i]\n",
    "            total_payoffs[i] = round(total_payoffs[i], 2)\n",
    "        \n",
    "        new_totals = [total_payoffs[i] for i in range(num_actions)]\n",
    "        totals_by_round.append(new_totals)\n",
    "        rounds_list.append(new_payoffs)\n",
    "\n",
    "    #print(\"utility at each round: \\n\", rounds_list)\n",
    "    #print(\"totals by round: \\n\", totals_by_round)\n",
    "    #print(\"final payoffs: \\n\", total_payoffs)\n",
    "    return rounds_list, totals_by_round\n",
    "\n",
    "#generate_bernoulli_payoffs(3, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9448fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_action_payoffs(action_payoffs):\n",
    "    copy_payoffs = [action_payoffs[i] for i in range(len(action_payoffs))]\n",
    "    for i in range(0, len(action_payoffs)):\n",
    "        action_payoffs[i] = copy_payoffs[i-1]\n",
    "    return action_payoffs\n",
    "\n",
    "def generate_rotational_random_payoffs(num_actions, num_rounds):\n",
    "    rounds_list = []\n",
    "    totals_by_round = []\n",
    "    action_payoffs = [round(random.random(), 2) for i in range(num_actions)]\n",
    "    total_payoffs = [0 for i in range(num_actions)]\n",
    "    \n",
    "    for i in range(num_rounds):\n",
    "        if random.random() > 0.9:\n",
    "            action_payoffs = rotate_action_payoffs(action_payoffs)\n",
    "            \n",
    "        for i in range(num_actions):\n",
    "            total_payoffs[i] += action_payoffs[i]\n",
    "            total_payoffs[i] = round(total_payoffs[i], 2)\n",
    "        new_totals = [total_payoffs[i] for i in range(num_actions)]    \n",
    "        rounds_list.append([action_payoffs[i] for i in range(num_actions)])\n",
    "        totals_by_round.append(new_totals)\n",
    "        \n",
    "    return rounds_list, totals_by_round\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9560f",
   "metadata": {},
   "source": [
    "## Simulate Algorithm Behavior Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56e3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_exponential_weights(rounds_list, totals_by_round, epsilon, max_payoff):\n",
    "    num_rounds = len(rounds_list)\n",
    "    num_actions = len(rounds_list[0])\n",
    "    choices_made = []\n",
    "    action_weights = []\n",
    "    action_probabilities = [(1/num_actions) for i in range(num_actions)]\n",
    "    current_weights = [1 for i in range(num_actions)]\n",
    "    action_weights.append(current_weights)\n",
    "    alg_payoffs = []\n",
    "    opt_payoffs = []\n",
    "    \n",
    "    for round in range(1, num_rounds):\n",
    "        last_round = round - 1\n",
    "        current_weights = [None for i in range(num_actions)]\n",
    "        for action in range(num_actions):\n",
    "            V_last = totals_by_round[last_round][action]\n",
    "            exp = V_last / max_payoff\n",
    "            current_weights[action] = pow(1 + epsilon, exp)\n",
    "        #randomly select from actions using weights as probabilities\n",
    "        selected_payoff = random.choices(rounds_list[round], weights=current_weights, k=1)[0]\n",
    "        alg_payoffs.append(selected_payoff)  \n",
    "        opt_payoffs.append(max(rounds_list[round]))\n",
    "        action_weights.append(current_weights)\n",
    "        \n",
    "    return alg_payoffs, totals_by_round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b382165f",
   "metadata": {},
   "source": [
    "## Monte Carlo Trials\n",
    "\n",
    "- Declare size of inputs\n",
    "- Generate payoffs\n",
    "- For each learning rate $\\{\\epsilon_1, . . ., \\epsilon_n\\}$\n",
    "    - For each input\n",
    "        - Simulate the algorithm\n",
    "        - calculate OPT (best in hindsight payoff)\n",
    "        - calculate the algorithm's regret\n",
    "    - Calculate the average regret for this learning rate $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "840628cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ALG regret for epsilon = 0 on adversarial distribution = 0.001316666666666668\n",
      "Average ALG regret for epsilon = 0.25 on adversarial distribution = 0.00764868686868688\n",
      "Average ALG regret for epsilon = 0.5 on adversarial distribution = 0.012354848484848482\n",
      "Average ALG regret for epsilon = 0.12686362411795196 on adversarial distribution = 0.004631717171717162\n",
      "Average ALG regret for epsilon = 0.75 on adversarial distribution = 0.016356464646464643\n",
      "Average ALG regret for epsilon = 1 on adversarial distribution = 0.018997676767676757\n",
      "Average ALG regret for epsilon = 100 on adversarial distribution = 0.08035363636363643\n",
      "Average ALG payoff for epsilon = 0 on adversarial distribution = 9.981869999999997\n",
      "Average ALG payoff for epsilon = 0.25 on adversarial distribution = 9.331530000000003\n",
      "Average ALG payoff for epsilon = 0.5 on adversarial distribution = 8.868879999999997\n",
      "Average ALG payoff for epsilon = 0.12686362411795196 on adversarial distribution = 9.637330000000004\n",
      "Average ALG payoff for epsilon = 0.75 on adversarial distribution = 8.464749999999995\n",
      "Average ALG payoff for epsilon = 1 on adversarial distribution = 8.192729999999994\n",
      "Average ALG payoff for epsilon = 100 on adversarial distribution = 2.06455\n",
      "Average OPT payoff for adversarial distribution = 10.31611000000001\n",
      "Average ALG regret for epsilon = 0 on bernoulli distribution = 0.17822222222222486\n",
      "Average ALG regret for epsilon = 0.25 on bernoulli distribution = 0.07359595959596073\n",
      "Average ALG regret for epsilon = 0.5 on bernoulli distribution = 0.05695959595959675\n",
      "Average ALG regret for epsilon = 0.12686362411795196 on bernoulli distribution = 0.1022929292929307\n",
      "Average ALG regret for epsilon = 0.75 on bernoulli distribution = 0.04997979797979865\n",
      "Average ALG regret for epsilon = 1 on bernoulli distribution = 0.04420202020202075\n",
      "Average ALG regret for epsilon = 100 on bernoulli distribution = 0.03547474747474783\n",
      "Average ALG payoff for epsilon = 0 on bernoulli distribution = 24.512\n",
      "Average ALG payoff for epsilon = 0.25 on bernoulli distribution = 35.014\n",
      "Average ALG payoff for epsilon = 0.5 on bernoulli distribution = 36.663\n",
      "Average ALG payoff for epsilon = 0.12686362411795196 on bernoulli distribution = 32.135\n",
      "Average ALG payoff for epsilon = 0.75 on bernoulli distribution = 37.354\n",
      "Average ALG payoff for epsilon = 1 on bernoulli distribution = 37.923\n",
      "Average ALG payoff for epsilon = 100 on bernoulli distribution = 38.783\n",
      "Average OPT payoff for bernoulli distribution = 42.309\n",
      "Average ALG regret for epsilon = 0 on rotational random distribution = 0.09954343434343436\n",
      "Average ALG regret for epsilon = 0.25 on rotational random distribution = 0.05726383838383839\n",
      "Average ALG regret for epsilon = 0.5 on rotational random distribution = 0.04372575757575755\n",
      "Average ALG regret for epsilon = 0.12686362411795196 on rotational random distribution = 0.07149404040404048\n",
      "Average ALG regret for epsilon = 0.75 on rotational random distribution = 0.037069898989899\n",
      "Average ALG regret for epsilon = 1 on rotational random distribution = 0.03316898989898985\n",
      "Average ALG regret for epsilon = 100 on rotational random distribution = 0.018435757575757585\n",
      "Average ALG payoff for epsilon = 0 on rotational random distribution = 50.540620000000025\n",
      "Average ALG payoff for epsilon = 0.25 on rotational random distribution = 54.75638000000005\n",
      "Average ALG payoff for epsilon = 0.5 on rotational random distribution = 56.101419999999926\n",
      "Average ALG payoff for epsilon = 0.12686362411795196 on rotational random distribution = 53.33372\n",
      "Average ALG payoff for epsilon = 0.75 on rotational random distribution = 56.764719999999926\n",
      "Average ALG payoff for epsilon = 1 on rotational random distribution = 57.15171000000001\n",
      "Average ALG payoff for epsilon = 100 on rotational random distribution = 58.60510000000005\n",
      "Average OPT payoff for rotational random distribution = 60.442780000000006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sum_to_round_i(alg_payoffs, current_round):\n",
    "    total = 0\n",
    "    for i in range(current_round):\n",
    "        total += alg_payoffs[i]\n",
    "    return total\n",
    "\n",
    "def individual_regrets(alg_payoffs, round_totals):\n",
    "    final_payoffs = round_totals[-1]\n",
    "    opt_action = final_payoffs.index(max(final_payoffs))\n",
    "    #print(opt_action)\n",
    "    individual_regrets = [0 for i in range(len(alg_payoffs))]\n",
    "    for round in range((len(alg_payoffs))):\n",
    "        individual_regrets[round] = (round_totals[round][opt_action] - sum_to_round_i(alg_payoffs, round)) / (round + 1)\n",
    "    return individual_regrets\n",
    "    \n",
    "\n",
    "rounds = 100\n",
    "actions = 5\n",
    "N = 1000\n",
    "# ADD OPTIMAL LEARNING RATE EPSILON\n",
    "opt_lr_eps = math.sqrt(numpy.log(actions)/rounds)\n",
    "learning_rates = [0, 0.25, 0.5, opt_lr_eps, 0.75, 1, 100]\n",
    "\n",
    "#adversarial monte carlo trial\n",
    "max_payoff = 1\n",
    "avg_lr_payoffs = dict()\n",
    "all_opt_payoffs = []\n",
    "avg_regret_per_round = dict()\n",
    "for n in range(N):\n",
    "    adversarial_payoffs, adversarial_totals = generate_adversarial_payoffs(actions, rounds)\n",
    "    for epsilon in learning_rates:\n",
    "        adv_payoffs, adv_round_totals = simulate_exponential_weights(adversarial_payoffs, adversarial_totals, epsilon, max_payoff)\n",
    "        adv_regrets = individual_regrets(adv_payoffs, adv_round_totals)\n",
    "        adv_avg_regrets = sum(adv_regrets) / len(adv_regrets)\n",
    "        adv_final_regret = adv_regrets[-1]\n",
    "        if epsilon not in avg_regret_per_round:\n",
    "            avg_regret_per_round[epsilon] = adv_regrets\n",
    "        else:\n",
    "            for i in range(len(avg_regret_per_round[epsilon])):\n",
    "                avg_regret_per_round[epsilon][i] = ((n * avg_regret_per_round[epsilon][i]) + adv_regrets[i]) / (n + 1)            \n",
    "        if epsilon not in avg_lr_payoffs:\n",
    "            avg_lr_payoffs[epsilon] = [sum(adv_payoffs)]\n",
    "        else:\n",
    "            avg_lr_payoffs[epsilon].append(sum(adv_payoffs))\n",
    "    all_opt_payoffs.append(max(adv_round_totals[-1]))\n",
    "for key, val in avg_regret_per_round.items():\n",
    "    print(\"Average ALG regret for epsilon =\", key, \"on adversarial distribution =\", val[-1])\n",
    "\n",
    "for key, val in avg_lr_payoffs.items():\n",
    "    print(\"Average ALG payoff for epsilon =\", key, \"on adversarial distribution =\", sum(val) / len(val))\n",
    "print(\"Average OPT payoff for adversarial distribution =\", sum(all_opt_payoffs) / len(all_opt_payoffs))  \n",
    "\n",
    "#bernoulli monte carlo trial\n",
    "max_payoff = 1\n",
    "avg_lr_payoffs = dict()\n",
    "all_opt_payoffs = []\n",
    "avg_regret_per_round = dict()\n",
    "for n in range(N):\n",
    "    bernoulli_payoffs, bernoulli_totals = generate_bernoulli_payoffs(actions, rounds)\n",
    "    for epsilon in learning_rates:\n",
    "        bern_payoffs, bern_round_totals = simulate_exponential_weights(bernoulli_payoffs, bernoulli_totals, epsilon, max_payoff)\n",
    "        bern_regrets = individual_regrets(bern_payoffs, bern_round_totals)\n",
    "        bern_avg_regrets = sum(bern_regrets) / len(bern_regrets)\n",
    "        bern_final_regret = bern_regrets[-1]\n",
    "        if epsilon not in avg_regret_per_round:\n",
    "            avg_regret_per_round[epsilon] = bern_regrets\n",
    "        else:\n",
    "            for i in range(len(avg_regret_per_round[epsilon])):\n",
    "                avg_regret_per_round[epsilon][i] = ((n * avg_regret_per_round[epsilon][i]) + bern_regrets[i]) / (n + 1)\n",
    "        \n",
    "        if epsilon not in avg_lr_payoffs:\n",
    "            avg_lr_payoffs[epsilon] = [sum(bern_payoffs)]\n",
    "        else:\n",
    "            avg_lr_payoffs[epsilon].append(sum(bern_payoffs))\n",
    "    \n",
    "    all_opt_payoffs.append(max(bern_round_totals[-1]))\n",
    "for key, val in avg_regret_per_round.items():\n",
    "    print(\"Average ALG regret for epsilon =\", key, \"on bernoulli distribution =\", val[-1])\n",
    "for key, val in avg_lr_payoffs.items():\n",
    "    print(\"Average ALG payoff for epsilon =\", key, \"on bernoulli distribution =\", sum(val) / len(val))\n",
    "print(\"Average OPT payoff for bernoulli distribution =\", sum(all_opt_payoffs) / len(all_opt_payoffs) )\n",
    "\n",
    "# rotational generation monte carlo trial\n",
    "generate_rotational_random_payoffs\n",
    "max_payoff = 1\n",
    "avg_lr_payoffs = dict()\n",
    "all_opt_payoffs = []\n",
    "avg_regret_per_round = dict()\n",
    "for n in range(N):\n",
    "    rotational_payoffs, rotational_totals = generate_rotational_random_payoffs(actions, rounds)\n",
    "    for epsilon in learning_rates:\n",
    "        rot_payoffs, rot_round_totals = simulate_exponential_weights(rotational_payoffs, rotational_totals, epsilon, max_payoff)\n",
    "        rot_regrets = individual_regrets(rot_payoffs, rot_round_totals)\n",
    "        rot_avg_regrets = sum(rot_regrets) / len(rot_regrets)\n",
    "        rot_final_regret = rot_regrets[-1]\n",
    "        if epsilon not in avg_regret_per_round:\n",
    "            avg_regret_per_round[epsilon] = rot_regrets\n",
    "        else:\n",
    "            for i in range(len(avg_regret_per_round[epsilon])):\n",
    "                avg_regret_per_round[epsilon][i] = ((n * avg_regret_per_round[epsilon][i]) + rot_regrets[i]) / (n + 1)\n",
    "        \n",
    "        if epsilon not in avg_lr_payoffs:\n",
    "            avg_lr_payoffs[epsilon] = [sum(rot_payoffs)]\n",
    "        else:\n",
    "            avg_lr_payoffs[epsilon].append(sum(rot_payoffs))\n",
    "    \n",
    "    all_opt_payoffs.append(max(rot_round_totals[-1]))\n",
    "for key, val in avg_regret_per_round.items():\n",
    "    print(\"Average ALG regret for epsilon =\", key, \"on rotational random distribution =\", val[-1])\n",
    "for key, val in avg_lr_payoffs.items():\n",
    "    print(\"Average ALG payoff for epsilon =\", key, \"on rotational random distribution =\", sum(val) / len(val))\n",
    "print(\"Average OPT payoff for rotational random distribution =\", sum(all_opt_payoffs) / len(all_opt_payoffs) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729ec07",
   "metadata": {},
   "source": [
    "# Data Cleaning Part 2C. Data in the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1106a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Day</th>\n",
       "      <th>payoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>47.28</td>\n",
       "      <td>47.340</td>\n",
       "      <td>46.135</td>\n",
       "      <td>46.30</td>\n",
       "      <td>6737752</td>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>46.63</td>\n",
       "      <td>47.435</td>\n",
       "      <td>46.350</td>\n",
       "      <td>46.70</td>\n",
       "      <td>5859604</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2</td>\n",
       "      <td>1.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>46.52</td>\n",
       "      <td>46.930</td>\n",
       "      <td>45.610</td>\n",
       "      <td>45.89</td>\n",
       "      <td>6825316</td>\n",
       "      <td>AAL</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>45.85</td>\n",
       "      <td>46.720</td>\n",
       "      <td>45.470</td>\n",
       "      <td>46.21</td>\n",
       "      <td>7260197</td>\n",
       "      <td>AAL</td>\n",
       "      <td>4</td>\n",
       "      <td>1.007852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>46.01</td>\n",
       "      <td>47.340</td>\n",
       "      <td>45.780</td>\n",
       "      <td>47.08</td>\n",
       "      <td>4739142</td>\n",
       "      <td>AAL</td>\n",
       "      <td>5</td>\n",
       "      <td>1.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619009</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>72.30</td>\n",
       "      <td>72.370</td>\n",
       "      <td>71.790</td>\n",
       "      <td>71.99</td>\n",
       "      <td>1345683</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>247</td>\n",
       "      <td>0.995712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619010</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>72.40</td>\n",
       "      <td>72.550</td>\n",
       "      <td>71.900</td>\n",
       "      <td>72.34</td>\n",
       "      <td>792134</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>248</td>\n",
       "      <td>0.999171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619011</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>72.59</td>\n",
       "      <td>72.690</td>\n",
       "      <td>72.250</td>\n",
       "      <td>72.45</td>\n",
       "      <td>1159771</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>249</td>\n",
       "      <td>0.998071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619012</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>72.49</td>\n",
       "      <td>72.600</td>\n",
       "      <td>72.140</td>\n",
       "      <td>72.39</td>\n",
       "      <td>710499</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>250</td>\n",
       "      <td>0.998620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619013</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>72.55</td>\n",
       "      <td>72.760</td>\n",
       "      <td>72.040</td>\n",
       "      <td>72.04</td>\n",
       "      <td>1704122</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>251</td>\n",
       "      <td>0.992970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126032 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   open    high     low  close   volume Name  Day    payoff\n",
       "982     2017-01-03  47.28  47.340  46.135  46.30  6737752  AAL    1  0.979272\n",
       "983     2017-01-04  46.63  47.435  46.350  46.70  5859604  AAL    2  1.001501\n",
       "984     2017-01-05  46.52  46.930  45.610  45.89  6825316  AAL    3  0.986457\n",
       "985     2017-01-06  45.85  46.720  45.470  46.21  7260197  AAL    4  1.007852\n",
       "986     2017-01-09  46.01  47.340  45.780  47.08  4739142  AAL    5  1.023256\n",
       "...            ...    ...     ...     ...    ...      ...  ...  ...       ...\n",
       "619009  2017-12-22  72.30  72.370  71.790  71.99  1345683  ZTS  247  0.995712\n",
       "619010  2017-12-26  72.40  72.550  71.900  72.34   792134  ZTS  248  0.999171\n",
       "619011  2017-12-27  72.59  72.690  72.250  72.45  1159771  ZTS  249  0.998071\n",
       "619012  2017-12-28  72.49  72.600  72.140  72.39   710499  ZTS  250  0.998620\n",
       "619013  2017-12-29  72.55  72.760  72.040  72.04  1704122  ZTS  251  0.992970\n",
       "\n",
       "[126032 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stock dataset taken from https://www.kaggle.com/datasets/camnugent/sandp500?select=all_stocks_5yr.csv\n",
    "\n",
    "df = pd.read_csv('all_stocks_5yr.csv') \n",
    "\n",
    "df = df.query('date.str.startswith(\"2017\")', \n",
    "engine=\"python\")\n",
    "\n",
    "df['Day']=df.groupby(['Name']).cumcount()+1\n",
    "\n",
    "#Add payoffs of each stock each day as column \n",
    "\n",
    "df['payoff'] = df['close'] / df['open']\n",
    "\n",
    "#Max payoff value\n",
    "\n",
    "df['payoff'].max()\n",
    "\n",
    "# get the number of total stocks\n",
    "df.drop_duplicates(subset = [\"Name\"]).shape[0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddcc127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify range of all stocks starting with A\n",
    "\n",
    "range_ds = df\n",
    "\n",
    "# get the unique values (rows)\n",
    "range_ds = range_ds.drop_duplicates(subset = [\"Name\"])\n",
    "\n",
    "#All stocks starting with A\n",
    "range_ds = range_ds.head(59)\n",
    "\n",
    "#first stock\n",
    "range_ds.head(1)['Name']\n",
    "\n",
    "#last stock\n",
    "range_ds.iloc[-1]['Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da96d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ALG regret for epsilon = 0 on rotational random distribution = 0.10266838383838378\n",
      "Average ALG regret for epsilon = 0.25 on rotational random distribution = 0.060758282828282925\n",
      "Average ALG regret for epsilon = 0.5 on rotational random distribution = 0.04565969696969706\n",
      "Average ALG regret for epsilon = 0.12686362411795196 on rotational random distribution = 0.0753458585858586\n",
      "Average ALG regret for epsilon = 0.75 on rotational random distribution = 0.038523737373737356\n",
      "Average ALG regret for epsilon = 1 on rotational random distribution = 0.03624151515151518\n",
      "Average ALG regret for epsilon = 100 on rotational random distribution = 0.018603131313131335\n",
      "Average ALG payoff for epsilon = 0 on rotational random distribution = 49.13597000000004\n",
      "Average ALG payoff for epsilon = 0.25 on rotational random distribution = 53.315120000000014\n",
      "Average ALG payoff for epsilon = 0.5 on rotational random distribution = 54.798780000000086\n",
      "Average ALG payoff for epsilon = 0.12686362411795196 on rotational random distribution = 51.84724999999999\n",
      "Average ALG payoff for epsilon = 0.75 on rotational random distribution = 55.51047000000001\n",
      "Average ALG payoff for epsilon = 1 on rotational random distribution = 55.73967000000004\n",
      "Average ALG payoff for epsilon = 100 on rotational random distribution = 57.48632999999997\n",
      "Average OPT payoff for rotational random distribution = 59.33896000000004\n"
     ]
    }
   ],
   "source": [
    "rounds = 251\n",
    "actions = 505\n",
    "N = 1000\n",
    "# ADD OPTIMAL LEARNING RATE EPSILON\n",
    "opt_lr_eps = math.sqrt(numpy.log(actions)/rounds)\n",
    "learning_rates = [0, 0.25, 0.5, opt_lr_eps, 0.75, 1, 100]\n",
    "\n",
    "max_payoff = 1.167806417674908 #max payoff of all stocks\n",
    "avg_lr_payoffs = dict()\n",
    "all_opt_payoffs = []\n",
    "avg_regret_per_round = dict()\n",
    "for n in range(N):\n",
    "    rotational_payoffs, rotational_totals = generate_rotational_random_payoffs(actions, rounds)\n",
    "    for epsilon in learning_rates:\n",
    "        rot_payoffs, rot_round_totals = simulate_exponential_weights(rotational_payoffs, rotational_totals, epsilon, max_payoff)\n",
    "        rot_regrets = individual_regrets(rot_payoffs, rot_round_totals)\n",
    "        rot_avg_regrets = sum(rot_regrets) / len(rot_regrets)\n",
    "        rot_final_regret = rot_regrets[-1]\n",
    "        if epsilon not in avg_regret_per_round:\n",
    "            avg_regret_per_round[epsilon] = rot_regrets\n",
    "        else:\n",
    "            for i in range(len(avg_regret_per_round[epsilon])):\n",
    "                avg_regret_per_round[epsilon][i] = ((n * avg_regret_per_round[epsilon][i]) + rot_regrets[i]) / (n + 1)\n",
    "        \n",
    "        if epsilon not in avg_lr_payoffs:\n",
    "            avg_lr_payoffs[epsilon] = [sum(rot_payoffs)]\n",
    "        else:\n",
    "            avg_lr_payoffs[epsilon].append(sum(rot_payoffs))\n",
    "    \n",
    "    all_opt_payoffs.append(max(rot_round_totals[-1]))\n",
    "for key, val in avg_regret_per_round.items():\n",
    "    print(\"Average ALG regret for epsilon =\", key, \"on rotational random distribution =\", val[-1])\n",
    "for key, val in avg_lr_payoffs.items():\n",
    "    print(\"Average ALG payoff for epsilon =\", key, \"on rotational random distribution =\", sum(val) / len(val))\n",
    "print(\"Average OPT payoff for rotational random distribution =\", sum(all_opt_payoffs) / len(all_opt_payoffs) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
